# AI UX Audit Checklist

**Created:** [Date]
**Week 7 Supporting Resource**
**Product Being Audited:** [Product Name]
**Audited By:** [Your Name]
**Date:** [Date]

---

## How to Use This Checklist

**Purpose:** Systematically evaluate AI product UX quality

**Instructions:**
1. Go through each category
2. Mark ✅ Yes, ❌ No, or ⚠️ Partial for each item
3. Add notes/observations
4. Calculate score for each category
5. Identify top improvement priorities
6. Create action plan

**Scoring:**
- ✅ Yes = 1 point
- ⚠️ Partial = 0.5 points
- ❌ No = 0 points

**Target Score:** 80%+ = Excellent AI UX

---

## Category 1: Clarity & Expectations (10 items)

### Does the product clearly communicate what the AI can do?

**1.1 Value Proposition**
- [ ] Clear explanation of what AI feature does
- [ ] Visible on first use
- [ ] Easy to understand for target user

**Score:** __ /1 | **Notes:**

---

**1.2 Capability Communication**
- [ ] Product shows examples of what AI can do
- [ ] Examples are relevant to user needs
- [ ] Examples are up-to-date

**Score:** __ /1 | **Notes:**

---

**1.3 Limitation Disclosure**
- [ ] Product explains what AI cannot do
- [ ] Limitations are honest and upfront
- [ ] Users understand edge cases

**Score:** __ /1 | **Notes:**

---

**1.4 First-Time User Experience**
- [ ] Onboarding explains AI features
- [ ] Tutorial or guided experience available
- [ ] Empty states suggest how to start

**Score:** __ /1 | **Notes:**

---

**1.5 Example Prompts/Inputs**
- [ ] Product provides example inputs
- [ ] Examples cover diverse use cases
- [ ] Easy to try examples (one-click)

**Score:** __ /1 | **Notes:**

---

**1.6 Expected Behavior**
- [ ] Users know what to expect from AI
- [ ] Loading/processing time is indicated
- [ ] Output format is previewed

**Score:** __ /1 | **Notes:**

---

**1.7 Discoverability**
- [ ] AI features are easy to find
- [ ] Not hidden in menus
- [ ] Contextually suggested when relevant

**Score:** __ /1 | **Notes:**

---

**1.8 Consistency**
- [ ] AI behavior is consistent across sessions
- [ ] Similar inputs produce similar outputs
- [ ] UI/UX is consistent throughout product

**Score:** __ /1 | **Notes:**

---

**1.9 Terminology**
- [ ] Uses plain language (not technical jargon)
- [ ] Terms are familiar to target users
- [ ] AI concepts are explained simply

**Score:** __ /1 | **Notes:**

---

**1.10 Help & Documentation**
- [ ] Help docs explain AI features
- [ ] FAQs address common questions
- [ ] Support is accessible

**Score:** __ /1 | **Notes:**

---

**Category 1 Total:** __ /10 (__%)

**Top Issue:** [What needs most improvement]

**Quick Win:** [Easiest fix]

---

## Category 2: Transparency (10 items)

### Does the product show how and why AI makes decisions?

**2.1 Confidence Indicators**
- [ ] AI shows how confident it is
- [ ] Confidence display is clear and understandable
- [ ] Low confidence is communicated

**Score:** __ /1 | **Notes:**

---

**2.2 Source Attribution**
- [ ] AI cites sources for factual claims
- [ ] Sources are clickable/verifiable
- [ ] Clear when AI is synthesizing vs. quoting

**Score:** __ /1 | **Notes:**

---

**2.3 Reasoning Explanation**
- [ ] AI explains why it made a recommendation
- [ ] Explanation is helpful (not generic)
- [ ] Users can access more detail if desired

**Score:** __ /1 | **Notes:**

---

**2.4 Alternative Options**
- [ ] AI shows other options it considered
- [ ] Alternatives are genuinely different
- [ ] Easy to explore alternatives

**Score:** __ /1 | **Notes:**

---

**2.5 Uncertainty Visualization**
- [ ] Uncertainty is shown (not hidden)
- [ ] Visual representation is clear
- [ ] Users understand when AI is guessing

**Score:** __ /1 | **Notes:**

---

**2.6 Data Source Transparency**
- [ ] Clear what data AI uses
- [ ] Users know if their data is used
- [ ] Privacy policy is accessible

**Score:** __ /1 | **Notes:**

---

**2.7 Model Information**
- [ ] Product discloses which AI model is used
- [ ] Last training date is available
- [ ] Known limitations are documented

**Score:** __ /1 | **Notes:**

---

**2.8 Personalization Explanation**
- [ ] Users understand how personalization works
- [ ] Can see why content is recommended to them
- [ ] Clear if based on history vs. general popularity

**Score:** __ /1 | **Notes:**

---

**2.9 Process Visibility**
- [ ] Users see what AI is doing (not black box)
- [ ] Multi-step processes are broken down
- [ ] Progress is communicated

**Score:** __ /1 | **Notes:**

---

**2.10 Version/Update Communication**
- [ ] Users notified when AI model updates
- [ ] Changes in behavior are explained
- [ ] Users can provide feedback on updates

**Score:** __ /1 | **Notes:**

---

**Category 2 Total:** __ /10 (__%)

**Top Issue:** [What needs most improvement]

**Quick Win:** [Easiest fix]

---

## Category 3: Control (10 items)

### Can users control and override AI?

**3.1 Automation Levels**
- [ ] Users can choose level of AI assistance
- [ ] Options include manual/suggest/copilot/auto
- [ ] Easy to switch between levels

**Score:** __ /1 | **Notes:**

---

**3.2 Edit Capability**
- [ ] All AI outputs are editable
- [ ] Editing is inline and intuitive
- [ ] Edits are saved properly

**Score:** __ /1 | **Notes:**

---

**3.3 Override Ability**
- [ ] Users can reject AI suggestions
- [ ] Override is easy (not buried)
- [ ] No penalty for overriding

**Score:** __ /1 | **Notes:**

---

**3.4 Undo/Redo**
- [ ] Easy to undo AI actions
- [ ] Undo is discoverable
- [ ] Can revert to previous version

**Score:** __ /1 | **Notes:**

---

**3.5 Customization**
- [ ] Users can customize AI behavior
- [ ] Settings are comprehensive
- [ ] Changes take effect immediately

**Score:** __ /1 | **Notes:**

---

**3.6 Preferences**
- [ ] Users can set tone/style preferences
- [ ] Preferences are remembered
- [ ] Easy to reset to defaults

**Score:** __ /1 | **Notes:**

---

**3.7 Feedback Mechanisms**
- [ ] Easy to give feedback (thumbs up/down)
- [ ] Detailed feedback option available
- [ ] Users see feedback impact

**Score:** __ /1 | **Notes:**

---

**3.8 Disable Option**
- [ ] Users can turn off AI features
- [ ] Easy to re-enable
- [ ] Product still works without AI

**Score:** __ /1 | **Notes:**

---

**3.9 Regeneration**
- [ ] Easy to regenerate AI outputs
- [ ] Can iterate with refinements
- [ ] Previous versions accessible

**Score:** __ /1 | **Notes:**

---

**3.10 Human Escalation**
- [ ] Clear path to human assistance
- [ ] Easy to request human review
- [ ] Response time is communicated

**Score:** __ /1 | **Notes:**

---

**Category 3 Total:** __ /10 (__%)

**Top Issue:** [What needs most improvement]

**Quick Win:** [Easiest fix]

---

## Category 4: Error Handling (10 items)

### How well does it handle failures and mistakes?

**4.1 Error Prevention**
- [ ] Product prevents errors proactively
- [ ] Validation happens before processing
- [ ] Clear input requirements

**Score:** __ /1 | **Notes:**

---

**4.2 Error Detection**
- [ ] Errors are detected quickly
- [ ] Users are notified immediately
- [ ] Error type is identified

**Score:** __ /1 | **Notes:**

---

**4.3 Error Messages**
- [ ] Error messages are helpful (not generic)
- [ ] Explain what went wrong
- [ ] Suggest how to fix

**Score:** __ /1 | **Notes:**

---

**4.4 Recovery Paths**
- [ ] Clear next steps after error
- [ ] Multiple recovery options
- [ ] User input is preserved

**Score:** __ /1 | **Notes:**

---

**4.5 Low Confidence Handling**
- [ ] AI communicates when unsure
- [ ] Asks for clarification
- [ ] Doesn't confidently give wrong answers

**Score:** __ /1 | **Notes:**

---

**4.6 Ambiguity Resolution**
- [ ] AI asks clarifying questions
- [ ] Questions are specific and helpful
- [ ] Doesn't make assumptions

**Score:** __ /1 | **Notes:**

---

**4.7 Graceful Degradation**
- [ ] Fallback when AI unavailable
- [ ] Manual mode works
- [ ] Useful error state (not blank)

**Score:** __ /1 | **Notes:**

---

**4.8 Timeout Handling**
- [ ] Long requests show progress
- [ ] Users can cancel if taking too long
- [ ] Timeout explained (not silent failure)

**Score:** __ /1 | **Notes:**

---

**4.9 Safety Violations**
- [ ] Inappropriate content is blocked
- [ ] Clear explanation why
- [ ] Alternative suggestions provided

**Score:** __ /1 | **Notes:**

---

**4.10 Learning from Errors**
- [ ] Product improves from user corrections
- [ ] Repeated errors are reduced
- [ ] Users see improvements

**Score:** __ /1 | **Notes:**

---

**Category 4 Total:** __ /10 (__%)

**Top Issue:** [What needs most improvement]

**Quick Win:** [Easiest fix]

---

## Category 5: Trust & Safety (10 items)

### Is the AI trustworthy and safe?

**5.1 Content Safety**
- [ ] Harmful content is blocked
- [ ] Content filters are effective
- [ ] Safety mechanisms are transparent

**Score:** __ /1 | **Notes:**

---

**5.2 Privacy Protection**
- [ ] User data is protected
- [ ] Clear privacy policy
- [ ] Users control their data

**Score:** __ /1 | **Notes:**

---

**5.3 PII Handling**
- [ ] Detects personal information
- [ ] Warns before processing PII
- [ ] Redacts PII in outputs

**Score:** __ /1 | **Notes:**

---

**5.4 Bias Mitigation**
- [ ] Product actively addresses bias
- [ ] Diverse outputs
- [ ] Users can report bias

**Score:** __ /1 | **Notes:**

---

**5.5 Factual Accuracy**
- [ ] AI is generally accurate
- [ ] Cites sources for facts
- [ ] Acknowledges uncertainty

**Score:** __ /1 | **Notes:**

---

**5.6 Hallucination Management**
- [ ] Product minimizes hallucinations
- [ ] Warns when potentially unreliable
- [ ] Encourages verification

**Score:** __ /1 | **Notes:**

---

**5.7 Security**
- [ ] Prompt injection prevented
- [ ] Rate limiting in place
- [ ] Abuse prevention mechanisms

**Score:** __ /1 | **Notes:**

---

**5.8 Accountability**
- [ ] Clear who's responsible (company vs. AI)
- [ ] Way to report issues
- [ ] Issues are addressed

**Score:** __ /1 | **Notes:**

---

**5.9 Consent**
- [ ] Users opt-in to AI features
- [ ] Clear about data usage
- [ ] Can opt-out easily

**Score:** __ /1 | **Notes:**

---

**5.10 Audit Trail**
- [ ] Users can see AI's past actions
- [ ] History is accessible
- [ ] Can review and correct

**Score:** __ /1 | **Notes:**

---

**Category 5 Total:** __ /10 (__%)

**Top Issue:** [What needs most improvement]

**Quick Win:** [Easiest fix]

---

## Category 6: Performance & Reliability (10 items)

### Is the AI fast and reliable?

**6.1 Response Time**
- [ ] Responses are timely (<5s for most)
- [ ] Meets user expectations
- [ ] Faster than manual alternative

**Score:** __ /1 | **Notes:**

---

**6.2 Loading States**
- [ ] Clear loading indicators
- [ ] Progress shown when possible
- [ ] Estimated time displayed

**Score:** __ /1 | **Notes:**

---

**6.3 Availability**
- [ ] Service is consistently available
- [ ] Uptime is high (>99%)
- [ ] Downtime is communicated

**Score:** __ /1 | **Notes:**

---

**6.4 Consistency**
- [ ] Similar queries yield similar results
- [ ] Quality doesn't fluctuate wildly
- [ ] Predictable behavior

**Score:** __ /1 | **Notes:**

---

**6.5 Scalability**
- [ ] Works well under load
- [ ] No degradation during peak times
- [ ] Queue management if needed

**Score:** __ /1 | **Notes:**

---

**6.6 Mobile Performance**
- [ ] Works well on mobile devices
- [ ] Responsive design
- [ ] Appropriate for smaller screens

**Score:** __ /1 | **Notes:**

---

**6.7 Offline Handling**
- [ ] Clear when offline
- [ ] Offline mode if applicable
- [ ] Graceful degradation

**Score:** __ /1 | **Notes:**

---

**6.8 Error Rate**
- [ ] Low error rate (<5%)
- [ ] Errors don't happen frequently
- [ ] Most requests succeed

**Score:** __ /1 | **Notes:**

---

**6.9 Quality Consistency**
- [ ] Output quality is reliable
- [ ] Rare terrible outputs
- [ ] Meets minimum quality bar

**Score:** __ /1 | **Notes:**

---

**6.10 Cost Efficiency**
- [ ] Pricing is reasonable
- [ ] Users get value for cost
- [ ] No unexpected charges

**Score:** __ /1 | **Notes:**

---

**Category 6 Total:** __ /10 (__%)

**Top Issue:** [What needs most improvement]

**Quick Win:** [Easiest fix]

---

## Category 7: User Experience (10 items)

### Is it delightful to use?

**7.1 Ease of Use**
- [ ] Intuitive interface
- [ ] Low learning curve
- [ ] Natural interaction

**Score:** __ /1 | **Notes:**

---

**7.2 Efficiency**
- [ ] Faster than manual alternative
- [ ] Reduces user effort
- [ ] Streamlines workflow

**Score:** __ /1 | **Notes:**

---

**7.3 Value Delivery**
- [ ] Solves real user problem
- [ ] Provides clear value
- [ ] Users would miss it if gone

**Score:** __ /1 | **Notes:**

---

**7.4 Integration**
- [ ] Fits naturally into workflow
- [ ] Doesn't disrupt existing processes
- [ ] Enhances current experience

**Score:** __ /1 | **Notes:**

---

**7.5 Accessibility**
- [ ] Works with screen readers
- [ ] Keyboard navigable
- [ ] Sufficient color contrast

**Score:** __ /1 | **Notes:**

---

**7.6 Visual Design**
- [ ] Polished visual design
- [ ] Professional appearance
- [ ] Attention to detail

**Score:** __ /1 | **Notes:**

---

**7.7 Delight Factor**
- [ ] Moments of delight
- [ ] Exceeds expectations
- [ ] Memorable experience

**Score:** __ /1 | **Notes:**

---

**7.8 Frustration Level**
- [ ] Low friction
- [ ] Minimal annoyances
- [ ] Rarely frustrates users

**Score:** __ /1 | **Notes:**

---

**7.9 Learnability**
- [ ] Easy to learn
- [ ] Gets easier with use
- [ ] Power features discoverable

**Score:** __ /1 | **Notes:**

---

**7.10 Satisfaction**
- [ ] Users are satisfied
- [ ] Positive reviews/feedback
- [ ] High NPS score

**Score:** __ /1 | **Notes:**

---

**Category 7 Total:** __ /10 (__%)

**Top Issue:** [What needs most improvement]

**Quick Win:** [Easiest fix]

---

## Overall Audit Summary

### Scores by Category

| Category | Score | Percentage | Grade |
|----------|-------|------------|-------|
| 1. Clarity & Expectations | __ /10 | __% | |
| 2. Transparency | __ /10 | __% | |
| 3. Control | __ /10 | __% | |
| 4. Error Handling | __ /10 | __% | |
| 5. Trust & Safety | __ /10 | __% | |
| 6. Performance & Reliability | __ /10 | __% | |
| 7. User Experience | __ /10 | __% | |
| **Overall** | **__ /70** | **__%** | |

**Grading Scale:**
- 90-100%: A (Excellent AI UX)
- 80-89%: B (Good AI UX)
- 70-79%: C (Acceptable AI UX)
- 60-69%: D (Needs Improvement)
- <60%: F (Poor AI UX)

---

### Overall Grade: __

**Overall Assessment:**
[2-3 sentences summarizing the product's AI UX quality]

---

### Strengths (Top 3)

1. **[Strength 1]**
   - Categories: [Which categories score high]
   - Examples: [Specific examples]
   - Why it matters: [Impact]

2. **[Strength 2]**
   - Categories:
   - Examples:
   - Why it matters:

3. **[Strength 3]**
   - Categories:
   - Examples:
   - Why it matters:

---

### Weaknesses (Top 3 Priority)

1. **[Weakness 1]**
   - Categories: [Which categories score low]
   - Examples: [Specific examples]
   - Impact: [Why this hurts UX]
   - Priority: P0 / P1 / P2
   - Recommended Fix: [What to do]

2. **[Weakness 2]**
   - Categories:
   - Examples:
   - Impact:
   - Priority:
   - Recommended Fix:

3. **[Weakness 3]**
   - Categories:
   - Examples:
   - Impact:
   - Priority:
   - Recommended Fix:

---

### Quick Wins (Easy + High Impact)

**Quick Win 1: [Name]**
- What: [What to change]
- Why: [Impact]
- Effort: Low / Medium / High
- Impact: Low / Medium / High
- Estimated Time: [Hours/Days]

**Quick Win 2: [Name]**
[Repeat structure]

**Quick Win 3: [Name]**
[Repeat structure]

---

### Long-Term Improvements

**Improvement 1: [Name]**
- What: [What to change]
- Why: [Impact]
- Effort: Low / Medium / High
- Impact: Low / Medium / High
- Timeline: [Weeks/Months]
- Dependencies: [What's needed]

**Improvement 2: [Name]**
[Repeat structure]

**Improvement 3: [Name]**
[Repeat structure]

---

## Action Plan

### Immediate (This Week)
- [ ] [Action 1 - Quick win]
- [ ] [Action 2 - Quick win]
- [ ] [Action 3 - Quick win]

### Short-Term (This Month)
- [ ] [Action 1 - P0 weakness]
- [ ] [Action 2 - P1 weakness]
- [ ] [Action 3 - Improvement]

### Medium-Term (3 Months)
- [ ] [Action 1 - Long-term improvement]
- [ ] [Action 2 - Long-term improvement]
- [ ] [Action 3 - Long-term improvement]

### Long-Term (6+ Months)
- [ ] [Strategic improvement 1]
- [ ] [Strategic improvement 2]
- [ ] [Strategic improvement 3]

---

## Comparison to Best-in-Class

### How Does This Compare to Top AI Products?

**Top Products in Category:**
- [Product 1 - e.g., ChatGPT]
- [Product 2 - e.g., GitHub Copilot]
- [Product 3 - e.g., Notion AI]

**Comparison:**

| Dimension | This Product | Best-in-Class | Gap |
|-----------|-------------|---------------|-----|
| Clarity | __% | ~90% | [Analysis] |
| Transparency | __% | ~85% | [Analysis] |
| Control | __% | ~90% | [Analysis] |
| Error Handling | __% | ~80% | [Analysis] |
| Trust & Safety | __% | ~95% | [Analysis] |
| Performance | __% | ~85% | [Analysis] |
| UX | __% | ~88% | [Analysis] |

**Key Insights:**
- [Insight 1 - Where this product excels]
- [Insight 2 - Where this product lags]
- [Insight 3 - Unique advantages]

---

## Interview Application

### How to Use This Audit in Interviews

**Question: "How do you evaluate AI product quality?"**

**Answer Framework:**
"I use a systematic audit framework covering 7 dimensions:

1. **Clarity** - Does it set proper expectations?
2. **Transparency** - Can users understand AI decisions?
3. **Control** - Can users override AI?
4. **Error Handling** - How well does it handle failures?
5. **Trust & Safety** - Is it safe and unbiased?
6. **Performance** - Is it fast and reliable?
7. **UX** - Is it delightful to use?

For [Product Name], I found it scored [X%] overall. Strengths were [Y] and [Z], but it needed improvement in [W]. I'd prioritize [specific improvement] because [impact]."

---

**Question: "What makes good AI UX?"**

**Answer:**
"Based on auditing [X] AI products, good AI UX has:

- **Clear expectations** - Users know what AI can/can't do
- **Transparency** - Shows confidence, sources, reasoning
- **User control** - Can override, customize, disable
- **Graceful errors** - Helpful messages, recovery paths
- **Safety** - Blocks harmful content, protects privacy
- **Performance** - Fast enough to be useful
- **Delight** - Makes users more effective

Bad AI UX is a black box that frustrates users and erodes trust."

---

**Question: "Critique [AI Product]'s UX"**

**Use your audit findings:**
- Start with 30-second summary (grade + top strength + top weakness)
- Give 2-3 specific examples
- Suggest 1-2 improvements
- Reference framework to show systematic thinking

---

## Appendix: Products Audited

Keep a log of products you've audited:

1. **[Product Name]** - [Date] - Score: __% - Key Learning: [X]
2. **[Product Name]** - [Date] - Score: __% - Key Learning: [X]
3. **[Product Name]** - [Date] - Score: __% - Key Learning: [X]

**Patterns Observed Across Products:**
- [Pattern 1]
- [Pattern 2]
- [Pattern 3]

---

**Goal:** Audit 5-10 AI products using this checklist to build pattern recognition and develop strong AI UX instincts.

**Recommended Products to Audit:**
- ChatGPT
- GitHub Copilot
- Notion AI
- Grammarly
- Midjourney
- Perplexity
- Claude
- Your own AI product
- 2-3 others in your domain

---

**This audit checklist is:**
- ✅ Comprehensive (70 evaluation points)
- ✅ Actionable (identifies specific improvements)
- ✅ Portfolio-worthy (demonstrates systematic thinking)
- ✅ Interview-ready (provides talking points)
- ✅ Repeatable (use on multiple products)

**Use this to:**
- Evaluate your own AI products
- Analyze competitors
- Prepare for interviews
- Build AI UX expertise
- Identify improvement opportunities
